# **NumPy核心函数用法笔记**

这份笔记聚焦于在实现注意力机制时常用到的几个关键NumPy函数，旨在厘清它们的功能、参数以及在多维数组（张量）操作中的具体应用。

## **1. np.matmul() - 矩阵乘法**

np.matmul() 用于执行两个数组的矩阵乘法。对于高维数组（维度 > 2），它的行为比较特殊。

- **核心规则**: 它将输入数组的**最后两个维度**视为矩阵进行乘法运算，而前面的维度被视为“批次”维度。
- **维度匹配要求**:

- 对于两个数组 A 和 B，要计算 np.matmul(A, B)，A 的倒数第一个维度（列数）必须等于 B 的倒数第二个维度（行数）。
- 所有在最后两个维度之前的“批次”维度必须是兼容的（要么完全相同，要么可以进行广播(broadcasting)）。

- **通用公式**: [..., a, b] @ [..., b, c] = [..., a, c]

**在注意力机制中的应用**:

\# Q 的形状: [batch_size, seq_len_q, depth]
\# K转置后 的形状: [batch_size, depth, seq_len_k]
\# 内部维度 depth 匹配
attention_scores = np.matmul(Q, K_transposed) 
\# 输出形状: [batch_size, seq_len_q, seq_len_k]



这里，matmul 在每个批次内独立计算查询矩阵 Q 和键矩阵 K 的乘积，以得到注意力分数。

## **2. np.transpose() - 维度换位**

np.transpose() 用于重排数组的维度。你可以指定一个新的维度顺序。

- **核心功能**: 改变数组维度的排列方式。
- **参数**: transpose(a, axes=None)

- a: 要操作的数组。
- axes: 一个元组或列表，定义了新的维度顺序。例如，[0, 2, 1] 表示将原先的第2个维度放到第1个维度的位置，第1个维度放到第2个维度的位置。

**在注意力机制中的应用**:

\# K 的原始形状: [batch_size, seq_len_k, depth]
\# 维度索引:   0     1     2

\# 我们需要将 depth 和 seq_len_k 交换位置
K_transposed = np.transpose(K, [0, 2, 1])

\# K 转置后的形状: [batch_size, depth, seq_len_k]



这个操作是计算注意力分数的关键前置步骤，它确保了 Q 和 K 在进行矩阵乘法时维度能够正确匹配。

## **3. np.concatenate() - 数组拼接**

np.concatenate() 用于沿着指定的轴（维度）将一系列数组拼接在一起。

- **核心功能**: 将多个数组合并成一个大数组。
- **参数**: concatenate((a1, a2, ...), axis=0)

- (a1, a2, ...): 一个包含待拼接数组的元组或列表。这些数组在拼接轴以外的所有维度上必须具有相同的形状。
- axis: 指定沿着哪个轴进行拼接。

**在多头注意力机制中的应用**:

\# 假设有两个头的输出，每个形状为 [1, 4, 4]
\# all_outputs = [output_head_1, output_head_2]

\# 沿着最后一个轴 (axis=-1，即特征维度) 进行拼接
concat_output = np.concatenate(all_outputs, axis=-1)

\# 拼接前: [1, 4, 4] 和 [1, 4, 4]
\# 拼接后: [1, 4, 8]



在多头注意力中，这个函数将所有独立计算的“头”的输出重新组合起来，恢复到模型原始的特征维度，同时融合了来自不同子空间的信息。

## **4. np.squeeze() - 移除单维度**

np.squeeze() 用于从数组的形状中移除大小为 1 的维度。

- **核心功能**: “压缩”数组，去掉多余的维度，简化数组的形状。
- **参数**: squeeze(a, axis=None)

- a: 要操作的数组。
- axis: 可选参数，指定只移除哪个轴。如果该轴的大小不为1，则会报错。如果不指定，则移除所有大小为1的维度。

**在结果可视化中的应用**:

\# 注意力权重的原始形状 (当批次为1时): [1, seq_len, seq_len]
attention_weights_squeezed = np.squeeze(attention_weights, axis=0)
\# 压缩后的形状: [seq_len, seq_len]



这个操作非常便于后续处理和可视化。例如，一个 [1, 8, 8] 的张量被压缩成 [8, 8] 的矩阵后，就可以直接用热力图等方式进行展示了。